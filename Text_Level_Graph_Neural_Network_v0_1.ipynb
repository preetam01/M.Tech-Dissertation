{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Level Graph Neural Network v0.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h8vgHcFx-at"
      },
      "source": [
        "# **# NLP Dataset: Twitter Sentiment Analysis**(Using Text Level GNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNSeFoTtfLtN"
      },
      "source": [
        "# **# 1. Import Libraries/Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFU742MMoxKS"
      },
      "source": [
        "# DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "#Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Utility\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # Import matplotlib for data visualisation\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#For glove\n",
        "import torch\n",
        "import torchtext\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-6Zgneo51Rt"
      },
      "source": [
        "# DATASET\n",
        "DATASET_COLUMNS = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "\n",
        "\n",
        "# TEXT CLENAING\n",
        "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDboIN7xxwzI"
      },
      "source": [
        "**#. Import Data Set for Sentiment Analysis using Googe Drive (Below is the backup option in case kaggle API having issues to load data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81RYU-OZ67Mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c690b8-684d-47b3-faae-fdaf260cb834"
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4crASGZjyw0H"
      },
      "source": [
        "dataset = pd.read_csv(r\"/content/drive/My Drive/Dissertation/Kaggle Sentiment140.csv\",encoding =DATASET_ENCODING , names=DATASET_COLUMNS)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuXa-LT_yjjJ"
      },
      "source": [
        "**#. Import Data Set for Sentiment Analysis directly from Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBkA55xzfKt0"
      },
      "source": [
        "#!mkdir -p ~/.kaggle"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4FPdBVOhxRy"
      },
      "source": [
        "#!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoo2URT9h2iq"
      },
      "source": [
        "#!ls ~/.kaggle"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gAUL51zfKFw"
      },
      "source": [
        "#!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AxVrUbmiJRr"
      },
      "source": [
        "#!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOT4gxeoiRIL"
      },
      "source": [
        "#!echo '{\"username\":\"preetamkumar\",\"key\":\"02e539250914c9fea2c057a45b87339b\"}' > /root/.kaggle/kaggle.json\n",
        "#!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxtVThkqin4t"
      },
      "source": [
        "#!kaggle datasets download -d kazanova/sentiment140 -p /content"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLlXKrDoiiIz"
      },
      "source": [
        "#!unzip \\*.zip"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmrWH-Myit1a"
      },
      "source": [
        "#dataset = pd.read_csv('training.1600000.processed.noemoticon.csv' , encoding =DATASET_ENCODING , names=DATASET_COLUMNS)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQGqm4-u64eo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eb6eea8-da76-49fa-dbaa-22698619508d"
      },
      "source": [
        "print(len(dataset))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jq3XdyfGc31",
        "outputId": "b5d19e46-2f08-455c-911d-3e6ed0797e1f"
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentiment', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "tmIOn3m8FTGM",
        "outputId": "ca8e3378-c89f-44d7-f99f-4c3835327d48"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1600000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentiment\n",
              "count  1600000.0\n",
              "mean         0.5\n",
              "std          0.5\n",
              "min          0.0\n",
              "25%          0.0\n",
              "50%          0.5\n",
              "75%          1.0\n",
              "max          1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ4L1oYi64h6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ddbaa97e-55e2-4dcb-d411-5501531b108d"
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A that s a bummer You shoulda got David Carr ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can t update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I dived many times for the ball  Managed to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>no  it s not behaving at all  i m mad  why am...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0   A that s a bummer You shoulda got David Carr ...\n",
              "1          0  is upset that he can t update his Facebook by ...\n",
              "2          0   I dived many times for the ball  Managed to s...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0   no  it s not behaving at all  i m mad  why am..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u0_pkFcQGMV-",
        "outputId": "2dbd870c-b958-4ad4-ede5-ec0064969c56"
      },
      "source": [
        "dataset.tail()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>1</td>\n",
              "      <td>Just woke up  Having no school is the best fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>1</td>\n",
              "      <td>TheWDB com Very cool to hear old Walt interviews</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>1</td>\n",
              "      <td>Are you ready for your MoJo Makeover  Ask me f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>1</td>\n",
              "      <td>Happy 38th Birthday to my boo of a  time Tupac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599999</th>\n",
              "      <td>1</td>\n",
              "      <td>happy  charitytuesday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         sentiment                                               text\n",
              "1599995          1  Just woke up  Having no school is the best fee...\n",
              "1599996          1  TheWDB com Very cool to hear old Walt interviews \n",
              "1599997          1  Are you ready for your MoJo Makeover  Ask me f...\n",
              "1599998          1  Happy 38th Birthday to my boo of a  time Tupac...\n",
              "1599999          1                             happy  charitytuesday "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDFws2Kc7LCu"
      },
      "source": [
        "# Removing the unnecessary columns.\n",
        "#dataset = dataset.drop(columns = [\"ids\", \"date\", \"flag\", \"user\"])"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUV4z1R37YsI"
      },
      "source": [
        "# **# 2. Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsLdhp8t8A9Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6db80b6b-d9d2-4fac-8031-997ebe86d01d"
      },
      "source": [
        "# Replacing the values to ease understanding.\n",
        "dataset['sentiment'] = dataset['sentiment'].replace(4,1)\n",
        "\n",
        "# Plotting the distribution for dataset.\n",
        "ax = dataset.groupby('sentiment').count().plot(kind='bar', title='Distribution of data',\n",
        "                                               legend=False)\n",
        "ax.set_xticklabels(['Negative','Positive'], rotation=0)\n",
        "\n",
        "# Storing data in lists.\n",
        "text, sentiment = list(dataset['text']), list(dataset['sentiment'])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAebUlEQVR4nO3de5QdZZ3u8e9jwiVyS4CeLEyCQcnoRBwQciAMOl6CIaBjcA5yOWoCZsgoqKPojOAwEwRRGI+ijBpPFkQSL0Bk9BAViBFwyXgM0CASAsPQckvCrUkCyF3wd/6oX0Ox2e/u3THZ3Umez1p77apfvfW+tUPTT9dlVykiMDMza+YVg70BZmY2dDkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwStsmQ9C1J/7KB+tpd0uOShuX8LyT93YboO/u7XNLMDdXfAMb9vKSHJT3QZvuQtOfG3i7bdA0f7A0wA5B0NzAaeA54HrgVWAjMi4g/AkTEhwfQ199FxM9LbSLiXmD7P22rXxjvNGDPiPhArf9DN0TfA9yO3YFPAa+OiIc2cN/jgbuArSLiuQ3Ztw1t3pOwoeRvImIH4NXAWcBngPM39CCSNtc/jnYH1mzogLAtm0PChpyIeDQiFgNHATMl7QUg6QJJn8/pXSX9RNIjktZKukbSKyR9h+qX5Y/zcNI/SRqfh1VmSboXuKpWqwfGayVdJ+kxSZdK2jnHepukVfVtlHS3pIMlTQM+CxyV4/02l79w+Cq361RJ90h6SNJCSTvlsr7tmCnp3jxU9M+lfxtJO+X6vdnfqdn/wcBS4FW5HRcU1v9HSfdLuk/ShxqWvUvSb/Lzr8w9pD6/zPdHsv8DJb1W0lWS1uR2f0/SyNK226bJIWFDVkRcB6wC3tJk8adyWRfVYarPVqvEB4F7qfZKto+If6ut81bgL4BDCkPOAD4E7EZ12OvcNrbxCuALwMU53t5Nmh2br7cDr6E6zPX1hjZvBl4HTAH+VdJfFIb8d2Cn7Oetuc3H5aG1Q4H7cjuObVwxA+3TwDuBCcDBDU2eyP5GAu8CPiLp8Fz21/k+Mvv/NSDgi8CrqP5dxwGnFbbbNlEOCRvq7gN2blL/A9Uv81dHxB8i4pro/0Zkp0XEExHxVGH5dyLiloh4AvgX4Mi+E9t/ovcDX4mIOyPiceAU4OiGvZjPRcRTEfFb4LfAy8Imt+Vo4JSI+H1E3A18Gfhgm9txJPDt2mc8rb4wIn4REcsj4o8RcTNwIVUQNRURPRGxNCKeiYhe4Cut2tumySFhQ90YYG2T+peAHuBnku6UdHIbfa0cwPJ7gK2AXdvaytZelf3V+x5OtQfUp3410pM0P6m+a25TY19jBrAdjZ/xBZIOkHR1Hsp6FPgwLT6/pNGSLpK0WtJjwHdbtbdNk0PChixJ/4PqF+B/Ni7Lv6Q/FRGvAd4DnCRpSt/iQpf97WmMq03vTrW38jDVYZhX1rZrGNVhrnb7vY/qZHy97+eAB/tZr9HDuU2Nfa1uc/37eflnrPs+sBgYFxE7Ad+iOqQEzT/jF7L+xojYEfhArb1tJhwSNuRI2lHSu4GLgO9GxPImbd4taU9JAh6lumz2j7n4Qapj9gP1AUkTJb0SOB24JCKeB/4b2DZP7G4FnApsU1vvQWC8pNL/TxcCn5S0h6TtefEcxoAuJc1tWQScKWkHSa8GTqL6C74di4Bja59xTsPyHYC1EfG0pP2B/1Vb1kv17/uahvaPA49KGgP840A+j20aHBI2lPxY0u+pDon8M9Ux7uMKbScAP6f6JfVr4JsRcXUu+yJwal759OkBjP8d4AKqQz/bAh+H6mor4ATgPKq/2p+gOmne5wf5vkbSjU36nZ99/5LquwZPAx8bwHbVfSzHv5NqD+v72X+/IuJy4KvAVVSH6q5qaHICcHr+N/hXqlDpW/dJ4EzgV/nvOhn4HLAvVUj/FPjhen4mG8Lkhw6ZmVmJ9yTMzKzIIWFmZkUOCTMzK3JImJlZ0WZ3o7Ndd901xo8fP9ibYWa2SbnhhhsejoiuxvpmFxLjx4+nu7t7sDfDzGyTIumeZnUfbjIzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWVFbISHpk5JWSLpF0oWSts3bHl8rqUfSxZK2zrbb5HxPLh9f6+eUrN8u6ZBafVrWeuoPjymNYWZmndFvSOR94j8OTIqIvYC+RyieDZwTEXsC64BZucosYF3Wz8l2SJqY670BmAZ8U9KwfIDLN6iezzsROCbb0mIMMzPrgHYPNw0HRuQzeV9J9YSrdwCX5PIFQN8D06fnPLl8Sj4YZjpwUT4P9y6q+9nvn6+efP7vs1QPmpme65TGMDOzDuj3G9cRsVrS/wbuBZ4CfgbcADxSe7LWKl58zu4Y8jm6EfFcPit3l6wvq3VdX2dlQ/2AXKc0xktImg3MBth998YnMg5N40/+6WBvwmbj7rPeNdibsFnxz+aGtan/fLZzuGkU1V7AHlQPUt+O6nDRkBER8yJiUkRM6up62a1HzMxsPbVzuOlg4K6I6I2IP1A9ovAgYGQefgIYy4sPY19NPmw9l+8ErKnXG9Yp1de0GMPMzDqgnZC4F5gs6ZV5nmAKcCtwNXBEtpkJXJrTi3OeXH5VVM9IXQwcnVc/7UH1jOLrgOuBCXkl09ZUJ7cX5zqlMczMrAP6DYmIuJbq5PGNwPJcZx7wGeAkST1U5w/Oz1XOB3bJ+knAydnPCqoHq98KXAGcGBHP5zmHjwJLgNuARdmWFmOYmVkHtHWr8IiYA8xpKN9JdWVSY9ungfcV+jkTOLNJ/TLgsib1pmOYmVln+BvXZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVmRQ8LMzIocEmZmVuSQMDOzIoeEmZkVOSTMzKzIIWFmZkUOCTMzK3JImJlZkUPCzMyK+g0JSa+TdFPt9ZikT0jaWdJSSXfk+6hsL0nnSuqRdLOkfWt9zcz2d0iaWavvJ2l5rnNuPiaV0hhmZtYZ7Ty+9PaI2Cci9gH2A54EfkT1WNIrI2ICcGXOAxxK9fzqCcBsYC5Uv/Cpnm53ANXT5ubUfunPBY6vrTct66UxzMysAwZ6uGkK8LuIuAeYDizI+gLg8JyeDiyMyjJgpKTdgEOApRGxNiLWAUuBablsx4hYFhEBLGzoq9kYZmbWAQMNiaOBC3N6dETcn9MPAKNzegywsrbOqqy1qq9qUm81hpmZdUDbISFpa+A9wA8al+UeQGzA7XqZVmNImi2pW1J3b2/vxtwMM7MtykD2JA4FboyIB3P+wTxURL4/lPXVwLjaemOz1qo+tkm91RgvERHzImJSREzq6uoawEcyM7NWBhISx/DioSaAxUDfFUozgUtr9Rl5ldNk4NE8ZLQEmCppVJ6wngosyWWPSZqcVzXNaOir2RhmZtYBw9tpJGk74J3A39fKZwGLJM0C7gGOzPplwGFAD9WVUMcBRMRaSWcA12e70yNibU6fAFwAjAAuz1erMczMrAPaComIeALYpaG2hupqp8a2AZxY6Gc+ML9JvRvYq0m96RhmZtYZ/sa1mZkVOSTMzKzIIWFmZkUOCTMzK3JImJlZkUPCzMyKHBJmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Mih4SZmRW1FRKSRkq6RNJ/SbpN0oGSdpa0VNId+T4q20rSuZJ6JN0sad9aPzOz/R2SZtbq+0lanuucm8+6pjSGmZl1Rrt7El8DroiI1wN7A7cBJwNXRsQE4MqcBzgUmJCv2cBcqH7hA3OAA4D9gTm1X/pzgeNr603LemkMMzPrgH5DQtJOwF8D5wNExLMR8QgwHViQzRYAh+f0dGBhVJYBIyXtBhwCLI2ItRGxDlgKTMtlO0bEsnw+9sKGvpqNYWZmHdDOnsQeQC/wbUm/kXSepO2A0RFxf7Z5ABid02OAlbX1V2WtVX1VkzotxngJSbMldUvq7u3tbeMjmZlZO9oJieHAvsDciHgT8AQNh31yDyA2/Oa1N0ZEzIuISRExqaura2NuhpnZFqWdkFgFrIqIa3P+EqrQeDAPFZHvD+Xy1cC42vpjs9aqPrZJnRZjmJlZB/QbEhHxALBS0uuyNAW4FVgM9F2hNBO4NKcXAzPyKqfJwKN5yGgJMFXSqDxhPRVYkssekzQ5r2qa0dBXszHMzKwDhrfZ7mPA9yRtDdwJHEcVMIskzQLuAY7MtpcBhwE9wJPZlohYK+kM4Ppsd3pErM3pE4ALgBHA5fkCOKswhpmZdUBbIRERNwGTmiya0qRtACcW+pkPzG9S7wb2alJf02wMMzPrDH/j2szMihwSZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVmRQ8LMzIocEmZmVuSQMDOzIoeEmZkVOSTMzKzIIWFmZkUOCTMzK3JImJlZkUPCzMyK2goJSXdLWi7pJkndWdtZ0lJJd+T7qKxL0rmSeiTdLGnfWj8zs/0dkmbW6vtl/z25rlqNYWZmnTGQPYm3R8Q+EdH3GNOTgSsjYgJwZc4DHApMyNdsYC5Uv/CBOcABwP7AnNov/bnA8bX1pvUzhpmZdcCfcrhpOrAgpxcAh9fqC6OyDBgpaTfgEGBpRKyNiHXAUmBaLtsxIpbl87EXNvTVbAwzM+uAdkMigJ9JukHS7KyNjoj7c/oBYHROjwFW1tZdlbVW9VVN6q3GeAlJsyV1S+ru7e1t8yOZmVl/hrfZ7s0RsVrSnwFLJf1XfWFEhKTY8JvX3hgRMQ+YBzBp0qSNuh1mZluStvYkImJ1vj8E/IjqnMKDeaiIfH8om68GxtVWH5u1VvWxTeq0GMPMzDqg35CQtJ2kHfqmganALcBioO8KpZnApTm9GJiRVzlNBh7NQ0ZLgKmSRuUJ66nAklz2mKTJeVXTjIa+mo1hZmYd0M7hptHAj/Kq1OHA9yPiCknXA4skzQLuAY7M9pcBhwE9wJPAcQARsVbSGcD12e70iFib0ycAFwAjgMvzBXBWYQwzM+uAfkMiIu4E9m5SXwNMaVIP4MRCX/OB+U3q3cBe7Y5hZmad4W9cm5lZkUPCzMyKHBJmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVlR2yEhaZik30j6Sc7vIelaST2SLpa0dda3yfmeXD6+1scpWb9d0iG1+rSs9Ug6uVZvOoaZmXXGQPYk/gG4rTZ/NnBOROwJrANmZX0WsC7r52Q7JE0EjgbeAEwDvpnBMwz4BnAoMBE4Jtu2GsPMzDqgrZCQNBZ4F3Bezgt4B3BJNlkAHJ7T03OeXD4l208HLoqIZyLiLqAH2D9fPRFxZ0Q8C1wETO9nDDMz64B29yS+CvwT8Mec3wV4JCKey/lVwJicHgOsBMjlj2b7F+oN65TqrcZ4CUmzJXVL6u7t7W3zI5mZWX/6DQlJ7wYeiogbOrA96yUi5kXEpIiY1NXVNdibY2a22RjeRpuDgPdIOgzYFtgR+BowUtLw/Et/LLA6268GxgGrJA0HdgLW1Op96us0q69pMYaZmXVAv3sSEXFKRIyNiPFUJ56vioj3A1cDR2SzmcClOb0458nlV0VEZP3ovPppD2ACcB1wPTAhr2TaOsdYnOuUxjAzsw74U74n8RngJEk9VOcPzs/6+cAuWT8JOBkgIlYAi4BbgSuAEyPi+dxL+CiwhOrqqUXZttUYZmbWAe0cbnpBRPwC+EVO30l1ZVJjm6eB9xXWPxM4s0n9MuCyJvWmY5iZWWf4G9dmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVmRQ8LMzIocEmZmVtRvSEjaVtJ1kn4raYWkz2V9D0nXSuqRdHE+n5p8hvXFWb9W0vhaX6dk/XZJh9Tq07LWI+nkWr3pGGZm1hnt7Ek8A7wjIvYG9gGmSZoMnA2cExF7AuuAWdl+FrAu6+dkOyRNBI4G3gBMA74paZikYcA3gEOBicAx2ZYWY5iZWQf0GxJReTxnt8pXAO8ALsn6AuDwnJ6e8+TyKZKU9Ysi4pmIuAvooXp+9f5AT0TcGRHPAhcB03Od0hhmZtYBbZ2TyL/4bwIeApYCvwMeiYjnsskqYExOjwFWAuTyR4Fd6vWGdUr1XVqM0bh9syV1S+ru7e1t5yOZmVkb2gqJiHg+IvYBxlL95f/6jbpVAxQR8yJiUkRM6urqGuzNMTPbbAzo6qaIeAS4GjgQGClpeC4aC6zO6dXAOIBcvhOwpl5vWKdUX9NiDDMz64B2rm7qkjQyp0cA7wRuowqLI7LZTODSnF6c8+TyqyIisn50Xv20BzABuA64HpiQVzJtTXVye3GuUxrDzMw6YHj/TdgNWJBXIb0CWBQRP5F0K3CRpM8DvwHOz/bnA9+R1AOspfqlT0SskLQIuBV4DjgxIp4HkPRRYAkwDJgfESuyr88UxjAzsw7oNyQi4mbgTU3qd1Kdn2isPw28r9DXmcCZTeqXAZe1O4aZmXWGv3FtZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVmRQ8LMzIocEmZmVuSQMDOzIoeEmZkVOSTMzKzIIWFmZkXtPON6nKSrJd0qaYWkf8j6zpKWSroj30dlXZLOldQj6WZJ+9b6mpnt75A0s1bfT9LyXOdcSWo1hpmZdUY7exLPAZ+KiInAZOBESROBk4ErI2ICcGXOAxwKTMjXbGAuVL/wgTnAAVSPJJ1T+6U/Fzi+tt60rJfGMDOzDug3JCLi/oi4Mad/D9wGjAGmAwuy2QLg8JyeDiyMyjJgpKTdgEOApRGxNiLWAUuBablsx4hYFhEBLGzoq9kYZmbWAQM6JyFpPPAm4FpgdETcn4seAEbn9BhgZW21VVlrVV/VpE6LMRq3a7akbkndvb29A/lIZmbWQtshIWl74D+AT0TEY/VluQcQG3jbXqLVGBExLyImRcSkrq6ujbkZZmZblLZCQtJWVAHxvYj4YZYfzENF5PtDWV8NjKutPjZrrepjm9RbjWFmZh3QztVNAs4HbouIr9QWLQb6rlCaCVxaq8/Iq5wmA4/mIaMlwFRJo/KE9VRgSS57TNLkHGtGQ1/NxjAzsw4Y3kabg4APAssl3ZS1zwJnAYskzQLuAY7MZZcBhwE9wJPAcQARsVbSGcD12e70iFib0ycAFwAjgMvzRYsxzMysA/oNiYj4T0CFxVOatA/gxEJf84H5TerdwF5N6muajWFmZp3hb1ybmVmRQ8LMzIocEmZmVuSQMDOzIoeEmZkVOSTMzKzIIWFmZkUOCTMzK3JImJlZkUPCzMyKHBJmZlbkkDAzsyKHhJmZFTkkzMysyCFhZmZFDgkzMytySJiZWVE7z7ieL+khSbfUajtLWirpjnwflXVJOldSj6SbJe1bW2dmtr9D0sxafT9Jy3Odc/M518UxzMysc9rZk7gAmNZQOxm4MiImAFfmPMChwIR8zQbmQvULH5gDHADsD8yp/dKfCxxfW29aP2OYmVmH9BsSEfFLYG1DeTqwIKcXAIfX6gujsgwYKWk34BBgaUSsjYh1wFJgWi7bMSKW5bOxFzb01WwMMzPrkPU9JzE6Iu7P6QeA0Tk9BlhZa7cqa63qq5rUW43xMpJmS+qW1N3b27seH8fMzJr5k09c5x5AbIBtWe8xImJeREyKiEldXV0bc1PMzLYo6xsSD+ahIvL9oayvBsbV2o3NWqv62Cb1VmOYmVmHrG9ILAb6rlCaCVxaq8/Iq5wmA4/mIaMlwFRJo/KE9VRgSS57TNLkvKppRkNfzcYwM7MOGd5fA0kXAm8DdpW0iuoqpbOARZJmAfcAR2bzy4DDgB7gSeA4gIhYK+kM4Ppsd3pE9J0MP4HqCqoRwOX5osUYZmbWIf2GREQcU1g0pUnbAE4s9DMfmN+k3g3s1aS+ptkYZmbWOf7GtZmZFTkkzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Mih4SZmRU5JMzMrMghYWZmRQ4JMzMrckiYmVmRQ8LMzIocEmZmVuSQMDOzIoeEmZkVDfmQkDRN0u2SeiSdPNjbY2a2JRnSISFpGPAN4FBgInCMpImDu1VmZluOIR0SwP5AT0TcGRHPAhcB0wd5m8zMthjDB3sD+jEGWFmbXwUc0NhI0mxgds4+Lun2DmzblmJX4OHB3ohWdPZgb4ENkiH/swmb1M/nq5sVh3pItCUi5gHzBns7NkeSuiNi0mBvh1kj/2x2xlA/3LQaGFebH5s1MzPrgKEeEtcDEyTtIWlr4Ghg8SBvk5nZFmNIH26KiOckfRRYAgwD5kfEikHerC2ND+PZUOWfzQ5QRAz2NpiZ2RA11A83mZnZIHJImJlZkUNiMyEpJH25Nv9pSadthHE+2zD//zb0GLZ5k/S8pJsk3SLpB5JeOcD1XyXpkpzeR9JhtWXv8e17NiyHxObjGeBvJe26kcd5SUhExF9t5PFs8/NUROwTEXsBzwIfHsjKEXFfRByRs/sAh9WWLY6IszbcpppDYvPxHNXVHp9sXCCpS9J/SLo+XwfV6kslrZB0nqR7+kJG0v+VdEMum521s4AR+Vfg97L2eL5fJOldtTEvkHSEpGGSvpTj3izp7zf6v4RtSq4B9pS0c/7M3SxpmaS/BJD01vx5u0nSbyTtIGl87oVsDZwOHJXLj5J0rKSvS9opf55fkf1sJ2mlpK0kvVbSFfnzfY2k1w/i5x/6IsKvzeAFPA7sCNwN7AR8Gjgtl30feHNO7w7cltNfB07J6WlAALvm/M75PgK4Bdilb5zGcfP9vcCCnN6a6nYqI6hul3Jq1rcBuoE9Bvvfy6/B/VnN9+HApcBHgH8H5mT9HcBNOf1j4KCc3j7XGQ/ckrVjga/X+n5hPvt+e04fBZyX01cCE3L6AOCqwf43GcqvIf09CRuYiHhM0kLg48BTtUUHAxMl9c3vKGl74M1Uv9yJiCskraut83FJ783pccAEYE2L4S8HviZpG6rA+WVEPCVpKvCXkvoOD+yUfd21vp/TNnkjJN2U09cA5wPXAv8TICKukrSLpB2BXwFfyT3XH0bEqtrPcX8upgqHq6m+iPvN/Ln/K+AHtX622QCfabPlkNj8fBW4Efh2rfYKYHJEPF1vWPqfTdLbqILlwIh4UtIvgG1bDRoRT2e7Q6j+x7yorzvgYxGxZKAfxDZbT0XEPvVC6WcxIs6S9FOq8w6/knQI8HTTxi+3GPiCpJ2B/YCrgO2ARxrHtzKfk9jMRMRaYBEwq1b+GfCxvhlJff+D/Ao4MmtTgVFZ3wlYlwHxemByra8/SNqqMPzFwHHAW4ArsrYE+EjfOpL+XNJ26/nxbPN1DfB+eOGPlIdzz/i1EbE8Is6muk1P4/mD3wM7NOswIh7Pdb4G/CQino+Ix4C7JL0vx5KkvTfKJ9pMOCQ2T1+muo1yn48Dk/Kk4K28eDXJ54Cpkm4B3gc8QPU/3RXAcEm3AWcBy2p9zQNu7jtx3eBnwFuBn0f1/A+A84BbgRtznP+D92Dt5U4D9pN0M9XP3MysfyJPUt8M/IHqsGbd1VSHUm+SdFSTfi8GPpDvfd4PzJL0W2AFfkZNS74txxYszx88H9U9sg4E5no33Mzq/Bfdlm13YFFeJvgscPwgb4+ZDTHekzAzsyKfkzAzsyKHhJmZFTkkzMysyCFhtgENxl1JJb1Nkm+0aBuFQ8JswxqMu5K+jepWE2YbnK9uMkv5TfBFwFiqZ6qfAfQAX6G6udzDwLERcX/eguRa4O3ASKpvuF+b7UcAq4Ev5vSkiPiopAuo7qn1JuDPgA8BM4ADgWsj4tjcjqlUX3TcBvgdcFxEPC7pbmAB8DfAVlRfgHya6suOzwO9VLdAuWZj/PvYlsl7EmYvmgbcFxF7R/Wsgyuo7k56RETsB8wHzqy1Hx4R+wOfoLqD6bPAvwIXR/W8hIt5uVFUofBJqnsLnQO8AXhjHqraFTgVODgi9qW6a+5JtfUfzvpc4NMRcTfwLeCcHNMBYRuUv0xn9qLlwJclnQ38BFgH7AUszRvQDQPur7X/Yb7fQHX76nb8OCJC0nLgwYhYDiBpRfYxFphIdTM7qG67/uvCmH87gM9mtl4cEmYpIv5b0r5U5xQ+T3XX0BURcWBhlWfy/Xna/3+pb50/1qb75odnX0sj4pgNOKbZevPhJrMk6VXAkxHxXeBLVA+k6cr7WpFPNXtDP90U70rapmXAQZL2zDG3k/TnG3lMsyKHhNmL3ghclw/EmUN1fuEI4Oy8Y+hN9H8VUX93JW0pInqpnq52Yd759Ne8/PbYjX4MvDfHfMtAxzRrxVc3mZlZkfckzMysyCFhZmZFDgkzMytySJiZWZFDwszMihwSZmZW5JAwM7Oi/w/NSRm0Vs5E1wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkdhLxmoMZ7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cec6ff9-d5ab-4b52-bada-d144a62fae3b"
      },
      "source": [
        "dataset.sentiment.unique()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9EnEdCCMbHm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "9b104151-6fd1-4018-81d6-0ef992a66d68"
      },
      "source": [
        "dataset.groupby('sentiment').nunique()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>777436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>769268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             text\n",
              "sentiment        \n",
              "0          777436\n",
              "1          769268"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAH04eId8Ffv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed1da20-85a2-4241-db1d-42aa1b6923a3"
      },
      "source": [
        "print (\"No of postive sentiment tweets:\")\n",
        "n_positive = len(dataset[dataset['sentiment'] == 1])\n",
        "print(n_positive)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of postive sentiment tweets:\n",
            "800000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdEm4E8l8J25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104ae2fc-ede3-4ea8-bc8a-6472bae0566e"
      },
      "source": [
        "print (\"No of negative sentiment tweets:\")\n",
        "n_negative = len(dataset[dataset['sentiment'] == 0])\n",
        "print(n_negative)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of negative sentiment tweets:\n",
            "800000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXjDhezp8Me_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "327e1ef9-3046-49ef-d376-ef20445c0716"
      },
      "source": [
        "# Print at least 2 tweets from each class of data set for the sanity check that labels match the text\n",
        "# Print +ve reviws\n",
        "print('Print at least 2 tweets from positive sentiment:')\n",
        "dataset_pos = dataset[dataset['sentiment'] == 1]\n",
        "dataset_pos.head(5)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print at least 2 tweets from positive sentiment:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>800000</th>\n",
              "      <td>1</td>\n",
              "      <td>I LOVE u guys r the best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800001</th>\n",
              "      <td>1</td>\n",
              "      <td>im meeting up with one of my besties tonight  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800002</th>\n",
              "      <td>1</td>\n",
              "      <td>Thanks for the Twitter add  Sunisa  I got to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800003</th>\n",
              "      <td>1</td>\n",
              "      <td>Being sick can be really cheap when it hurts t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800004</th>\n",
              "      <td>1</td>\n",
              "      <td>he has that effect on everyone</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment                                               text\n",
              "800000          1                          I LOVE u guys r the best \n",
              "800001          1  im meeting up with one of my besties tonight  ...\n",
              "800002          1   Thanks for the Twitter add  Sunisa  I got to ...\n",
              "800003          1  Being sick can be really cheap when it hurts t...\n",
              "800004          1                    he has that effect on everyone "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La5OXE4j8PdS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "88fadc63-5aa5-4aa4-893d-69ad81d84288"
      },
      "source": [
        "# Print at least 2 tweets from each class of data set for the sanity check that labels match the text\n",
        "# Print -ve reviws\n",
        "print('Print at least 2 tweets from negative sentiment:')\n",
        "dataset_neg = dataset[dataset['sentiment'] == 0]\n",
        "dataset_neg.head(5)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print at least 2 tweets from negative sentiment:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A that s a bummer You shoulda got David Carr ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can t update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I dived many times for the ball  Managed to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>no  it s not behaving at all  i m mad  why am...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0   A that s a bummer You shoulda got David Carr ...\n",
              "1          0  is upset that he can t update his Facebook by ...\n",
              "2          0   I dived many times for the ball  Managed to s...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0   no  it s not behaving at all  i m mad  why am..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avTwHNUJ8XCZ"
      },
      "source": [
        "# **#3. Data Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSZBL_y28ZhR"
      },
      "source": [
        "# Defining dictionary containing all emojis with their meanings.\n",
        "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
        "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
        "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
        "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
        "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
        "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
        "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj0vTDm38gCg"
      },
      "source": [
        "#Removing Twitter Handles(@user)\n",
        "#User Defined function to remove patten\n",
        "#Removing Twitter Handles(@user)\n",
        "#User Defined function to remove patten\n",
        "#Removing Emojis\n",
        "\n",
        "def preprocess(tweet):\n",
        "    # Defining regex patterns.\n",
        "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "    userPattern       = '@[^\\s]+'\n",
        "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
        "    sequencePattern   = r\"(.)\\1\\1+\"\n",
        "        \n",
        "                  \n",
        "    # Replace all URls with 'URL'\n",
        "    tweet = re.sub(urlPattern,' URL',tweet)\n",
        "     # Replace all emojis.\n",
        "    for emoji in emojis.keys():\n",
        "        tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
        "    # Replace @USERNAME to 'USER'.\n",
        "    tweet = re.sub(userPattern,' USER', tweet)        \n",
        "    # Replace all non alphabets.\n",
        "    tweet = re.sub(alphaPattern, \" \", tweet)\n",
        "    \n",
        "    return tweet"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbhFhw8r8heU"
      },
      "source": [
        "dataset['text'] = dataset['text'].apply(preprocess)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL7AEGtH81JS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "11e9f647-d2bf-416d-8884-ae5eeffbbf62"
      },
      "source": [
        "#dataset1 = dataset\n",
        "dataset.head(5)\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A that s a bummer You shoulda got David Carr ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can t update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I dived many times for the ball  Managed to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>no  it s not behaving at all  i m mad  why am...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0   A that s a bummer You shoulda got David Carr ...\n",
              "1          0  is upset that he can t update his Facebook by ...\n",
              "2          0   I dived many times for the ball  Managed to s...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0   no  it s not behaving at all  i m mad  why am..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c62rZtViaOxv"
      },
      "source": [
        "def preprocess_2(tweet):\n",
        "      sequencePattern   = r\"(.)\\1\\1+\"\n",
        "      tweet = re.sub('www',' ', tweet)   \n",
        "      tweet = re.sub('WWW',' ', tweet)\n",
        "      tweet = re.sub('USER',' ', tweet)\n",
        "      tweet = re.sub('user',' ', tweet)\n",
        "      tweet = re.sub('URL',' ', tweet)\n",
        "      tweet = re.sub('url',' ', tweet)   \n",
        "       # Replace 3 or more consecutive letters by ' '.\n",
        "      tweet = re.sub(sequencePattern,' ',  tweet)\n",
        "      return tweet"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0GuCkQtciT1"
      },
      "source": [
        "dataset['text'] = dataset['text'].apply(preprocess_2)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm0W_YeZcoDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c577f8e1-4e32-452a-974a-13ac803562ef"
      },
      "source": [
        "print(len(dataset))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1600000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm3uTZtj-_wq",
        "outputId": "d8f83a24-e75b-439c-ded6-db452b33d42b"
      },
      "source": [
        "dataset_sentiment = dataset.sentiment\n",
        "dataset_text = dataset.text\n",
        "dataset_text.head(5)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     A that s a bummer You shoulda got David Carr ...\n",
              "1    is upset that he can t update his Facebook by ...\n",
              "2     I dived many times for the ball  Managed to s...\n",
              "3      my whole body feels itchy and like its on fire \n",
              "4     no  it s not behaving at all  i m mad  why am...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "senlESiZUiUu",
        "outputId": "b3f2152d-d596-424b-f700-a7adbf03eda5"
      },
      "source": [
        "dataset_text = dataset_text[:1000]\n",
        "dataset_sentiment = dataset_sentiment[:1000]\n",
        "print(len(dataset_text))\n",
        "dataset_text.head(5)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     A that s a bummer You shoulda got David Carr ...\n",
              "1    is upset that he can t update his Facebook by ...\n",
              "2     I dived many times for the ball  Managed to s...\n",
              "3      my whole body feels itchy and like its on fire \n",
              "4     no  it s not behaving at all  i m mad  why am...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uiZKjrNZcMt"
      },
      "source": [
        "#Creation of Text Level Graph\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "def text_level_graph(node,p,n):\n",
        "  G = nx.Graph()\n",
        "  G.add_nodes_from(node)\n",
        "\n",
        "#Creating the edges from the node list based on value of p (i.e. if p =2 then each node is connected to previous 2 nodes.). \n",
        "  edge = []\n",
        "  \n",
        "\n",
        "  for i in range (0,(len(node)-1)):\n",
        "      for j in range (1,(p+1)):\n",
        "          if((i+j)< len(node) ):\n",
        "              edge.append([node[i],node[i+j]])\n",
        "\n",
        "#Add edges to the graph from the edge lsit.\n",
        "  G.add_edges_from(edge)\n",
        "  Adj_Matrix = nx.to_numpy_matrix(G)\n",
        "  Adj_Matrix = np.array(Adj_Matrix)\n",
        "  \n",
        "  # return Adj_Matrix\n",
        "  #Node embedding function\n",
        "  x= len(node)\n",
        "  y = 100 #Number of Dimension for Node embedding\n",
        "  w2v = np.empty((x,y), float)\n",
        "  for i in range (0, len(node)):\n",
        "    if (i< len(node)):\n",
        "      T = glove[node[i]]\n",
        "      Vec = T.numpy()\n",
        "      w2v[i] = Vec\n",
        "  x= len(node)+1\n",
        "  y = 100 #Number of Dimension for Node embedding\n",
        "  Mn_Temp = np.empty((4,y),float) # Temporary Matrix to hold the calculation of w2v[row] * edge[i][j] weight\n",
        "  Mn = np.empty((1,100), float) #Matrix to captur the highestest value in each dimension for each node(word) processing\n",
        "  w2v_new_Temp = np.empty((x,y), float)#Matrix to capture all Mn for each node(word) in the graph \n",
        "  w2v_new= np.empty((x,y), float)#Final word embeddd Matrix to capture updated with message passing from linked nodes(words)\n",
        "  \n",
        "\n",
        "#def msg_pass(node,n):    # n is a trainable variable(value between 0 to 1) for node n that indicates how much information of rn should be kept\n",
        "  for i in range (0, x):\n",
        "    for j in range ((i-2), (i+3)):\n",
        "      if ((j <= p) & (j != i) & (j>=0)):\n",
        "        Mn_Temp[j] = Adj_Matrix[i][j]*w2v[i]\n",
        "      Mn = np.amax(Mn_Temp, axis = 0)\n",
        "      w2v_new_Temp[i]= Mn\n",
        " \n",
        "  w2v_new = (1-n)*w2v_new_Temp + n*w2v\n",
        "\n",
        "  n1 = w2v_new.shape[0]-1 #Determine the no of rows in the w2v_new matrix. This value will be used to inform the no of iteration for the \n",
        "  #for loop to add the elements of a column together.\n",
        "\n",
        "  node_emb_total = np.empty((1,100), float) # Define the Numpay Array(Matrix) with a dimension of 1 x 100 to capture the final node embedding value post msg passign aggregation.\n",
        "\n",
        "  for i in (0,n1):\n",
        "    node_emb_total[0] = node_emb_total[0] + w2v_new[i]\n",
        "  return node_emb_total"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJP742uMkAsP"
      },
      "source": [
        "#Node embedding function\n",
        "def node_embedding(node):\n",
        "  x= len(node)\n",
        "  y = 100 #Number of Dimension for Node embedding\n",
        "  w2v = np.empty((x,y), float)\n",
        "  for i in range (0, len(node)):\n",
        "    if (i< len(node)):\n",
        "      T = glove[node[i]]\n",
        "      Vec = T.numpy()\n",
        "      w2v[i] = Vec"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "451KMy2-kitL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "6e873c1d-62e1-4873-92e8-eb0d772153ab"
      },
      "source": [
        "#Message Passing between the nodes of the text level graph\n",
        "\n",
        "x= len(node)\n",
        "y = 100 #Number of Dimension for Node embedding\n",
        "Mn_Temp = np.empty((4,y),float) # Temporary Matrix to hold the calculation of w2v[row] * edge[i][j] weight\n",
        "Mn = np.empty((1,100), float) #Matrix to captur the highestest value in each dimension for each node(word) processing\n",
        "w2v_new_Temp = np.empty((x,y), float)#Matrix to capture all Mn for each node(word) in the graph \n",
        "w2v_new= np.empty((x,y), float)#Final word embeddd Matrix to capture updated with message passing from linked nodes(words)\n",
        "node=[]\n",
        "\n",
        "def msg_pass(node,n):    # n is a trainable variable(value between 0 to 1) for node n that indicates how much information of rn should be kept\n",
        "  for i in range (0, len(node)):\n",
        "    for j in range ((i-2), (i+3)):\n",
        "      if ((j <= p) & (j != i) & (j>=0)):\n",
        "        Mn_Temp[j] = Adj_Mat[i][j]*w2v[i]\n",
        "      Mn = np.amax(Mn_Temp, axis = 0)\n",
        "      w2v_new_Temp[i]= Mn\n",
        " \n",
        "  w2v_new = (1-n)*w2v_new_Temp + n*w2v\n",
        "  return w2v_new\n",
        "  \n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-c38780a8b3c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Message Passing between the nodes of the text level graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;31m#Number of Dimension for Node embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMn_Temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Temporary Matrix to hold the calculation of w2v[row] * edge[i][j] weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'node' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnBnhpn9bSi5",
        "outputId": "d453dd47-ad8d-469c-e633-4dc8d773aaca"
      },
      "source": [
        "glove = torchtext.vocab.GloVe(name=\"6B\", # trained on Wikipedia 2014 corpus\n",
        "                              dim=100)   # embedding size = 100"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:50, 5.07MB/s]                           \n",
            "100%|█████████▉| 399737/400000 [00:17<00:00, 22058.94it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG3T6ZbbS-9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ef404668-a8ef-4427-e0fe-4b9f5bbf3719"
      },
      "source": [
        "l = len(dataset_text) # No of rows in dataset which will be use for the no iteration to prepare the text level graph\n",
        "p=2\n",
        "n = 0.5\n",
        "TG_w2v_Matrix_final = np.empty((l,100),float) #Define the final Text Level W2V matrix after message passing agreegation. Which will be input feature matrix to ML model\n",
        "\n",
        "for i in range (0, l):\n",
        "  node = dataset_text[i].split()\n",
        "  TG_w2v_Matrix_final[i] = text_level_graph(node,p,n)\n",
        " \n",
        "\n",
        "  "
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-900328950c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mTG_w2v_Matrix_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_level_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-74ff98095580>\u001b[0m in \u001b[0;36mtext_level_graph\u001b[0;34m(node, p, n)\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mw2v_new_Temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0mw2v_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw2v_new_Temp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m#Determine the no of rows in the w2v_new matrix. This value will be used to inform the no of iteration for the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (18,100) (17,100) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKoMGwsZ1h9g"
      },
      "source": [
        "TG_w2v_Matrix_final.shape[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hINbcmfaGfzM"
      },
      "source": [
        "dataset_sentiment.to_numpy()\n",
        "dataset_sentiment.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln2QNClzhS77"
      },
      "source": [
        "#**#4.Model Building**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG9pK-_7WBg1"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(TG_w2v_Matrix_final, dataset_sentiment, test_size=0.2, random_state=37)\n",
        "print('# Train data samples:', X_train.shape[0])\n",
        "print('# Test data samples:', X_test.shape[0])\n",
        "assert X_train.shape[0] == Y_train.shape[0]\n",
        "assert X_test.shape[0] == Y_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD-log_fWpxp"
      },
      "source": [
        "#Print the head to check the X_train dataset\n",
        "Y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krp3Zgw0JmO4"
      },
      "source": [
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USBSYMZCshyj"
      },
      "source": [
        "#Define a function for the loss function\n",
        "\n",
        "# Initialize weight parameter to all 1 and bias(number of classes) to 0.\n",
        "num_features = 100\n",
        "num_classes = len(np.unique(dataset_sentiment))\n",
        "\n",
        "W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\n",
        "b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")\n",
        "\n",
        "\n",
        "def logistic_regression (x):\n",
        "  y_pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
        "  return y_pred\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "  y_true = tf.one_hot(y_true, depth=num_classes) #Encode label to a one hot vector.\n",
        "  y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "  loss = tf.reduce_mean(-tf.reduce_sum( y_true * tf.math.log(y_pred))) ## Clip prediction values to avoid log(0) error.\n",
        "  return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeDGqDJVl0ww"
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "X_train = tf.cast(X_train, tf.float32)\n",
        "# Y_train = tf.cast(Y_train,tf.int32)\n",
        "X_test  = tf.cast(X_test, tf.float32)\n",
        "# Y_test  = tf.cast(Y_test, tf.int32)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P51xzA1rc-V-"
      },
      "source": [
        "y_pred = logistic_regression(X_train)\n",
        "loss = cross_entropy_loss(Y_train, y_pred)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmuK5QI2C2fn"
      },
      "source": [
        "# Accuracy metric is a function to choose the correct prediction. Compute the output, it gives us the probability of the given data to fit a particular class of output.\n",
        "# Consider the correct prediction as  the class having the highest probability. We compute this using the function tf.argmax.\n",
        "\n",
        "def accuracy(y_pred, y_true):\n",
        "\n",
        "# Predicted class is the index of the highest score in prediction vector (i.e. argmax).\n",
        "\n",
        "  correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  return accuracy\n",
        "\n",
        "# Stochastic gradient descent optimizer.\n",
        "learning_rate = 0.00001\n",
        "optimizer = tf.optimizers.SGD(learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGx5tG0v4CpB"
      },
      "source": [
        "**Model Building using Keras Tensor Flow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRvnEQY5HFnb"
      },
      "source": [
        "# Optimization process. \n",
        "\n",
        "def run_optimization(x, y):\n",
        "\n",
        "# Wrap computation inside a GradientTape for automatic differentiation.\n",
        "\n",
        "    with tf.GradientTape() as g:\n",
        "\n",
        "        pred = logistic_regression(x)\n",
        "\n",
        "        loss = cross_entropy_loss (y, pred)\n",
        "\n",
        "    # Compute gradients.\n",
        "\n",
        "    gradients = g.gradient(loss, [W, b])\n",
        "\n",
        "  \n",
        "\n",
        "    # Update W and b following gradients.\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, [W,b]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obhN_C5SHK0x"
      },
      "source": [
        "# Run training for the given number of steps.\n",
        "# Training parameters.\n",
        "epochs = 2\n",
        "learning_rate = 0.01\n",
        "\n",
        "training_steps = 1000\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "display_step = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "    for step, (batch_x, batch_y) in enumerate(train_dataset.take(training_steps), 1):\n",
        "\n",
        "        # Run the optimization to update W and b values.\n",
        "\n",
        "        run_optimization(batch_x, batch_y)\n",
        "\n",
        "        \n",
        "\n",
        "        if step % display_step == 0:\n",
        "\n",
        "          pred = logistic_regression(batch_x)\n",
        "\n",
        "          loss = cross_entropy_loss(batch_y, pred)\n",
        "\n",
        "          acc = accuracy(pred, batch_y)\n",
        "\n",
        "          print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoHP736AUsh_"
      },
      "source": [
        "# Test model on validation set.\n",
        "\n",
        "pred = logistic_regression(X_test)\n",
        "\n",
        "print(\"Test Accuracy: %f\" % accuracy(pred, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX-6u65RnXxt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkB_B10CGpCY"
      },
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from keras.regularizers import L1L2\n",
        "# model = Sequential()\n",
        "# model.add(Dense(2,  # output dim is 2, one score per each class\n",
        "#                 activation='softmax',\n",
        "#                 kernel_regularizer=L1L2(l1=0.0, l2=0.1),\n",
        "#                 input_dim= 100  # input dimension = number of features your data has\n",
        "\n",
        "# model.compile (optimizer='sdg',\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# model.fit(X_train, y_train, epochs=100, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6zNHlhNQtG3"
      },
      "source": [
        "> a) Sequential Model Layer - Use at LEAST 3 dense layers with appropriate input for each. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XucP8O3XbGI9"
      },
      "source": [
        "# hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\", output_shape=[128], \n",
        "#                            input_shape=[], dtype=tf.string)\n",
        "# model_1 = keras.Sequential()\n",
        "# model_1.add(hub_layer)\n",
        "# model_1.add(keras.layers.Dense(100, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "# model_1.add(keras.layers.Dropout(0.5))\n",
        "# model_1.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "# model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCck8_nW23MV"
      },
      "source": [
        "#**#5.Model Compilation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8iXUOCwgOdW"
      },
      "source": [
        "# a) Compile the model with appropriate loss function \n",
        "### lost function used : BinaryCrossentropy \n",
        "# b) Use an appropriate optimizer. - \"Adam\" optimizer is used so that Adam combines the \n",
        "#    best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients and no need\n",
        "#    to define learning rate manually.\n",
        "\n",
        "# opt = Adam(lr=0.01)\n",
        "# model_1.compile(optimizer = opt, loss ='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpU1NYxs3CB_"
      },
      "source": [
        "#**#6.Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19qGxC5ej07M"
      },
      "source": [
        "# no_of_epcohs = 15\n",
        "# gradient_batch_size = 128\n",
        "\n",
        "# history1 = model_1.fit(X_train, \n",
        "#                    y_train,\n",
        "#                    validation_split = 0.2,\n",
        "#                    steps_per_epoch = 5,\n",
        "#                    epochs=no_of_epcohs,\n",
        "#                    batch_size=gradient_batch_size, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cktz3vHvB4b8"
      },
      "source": [
        "\n",
        "# def plot_history(history):\n",
        "#     loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
        "#     val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
        "#     acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
        "#     val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
        "    \n",
        "#     if len(loss_list) == 0:\n",
        "#         print('Loss N/A')\n",
        "#         return \n",
        "    \n",
        "#     ## As loss always exists\n",
        "#     epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
        "    \n",
        "#     ## Loss\n",
        "#     plt.figure(1)\n",
        "#     for l in loss_list:\n",
        "#         plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "#     for l in val_loss_list:\n",
        "#         plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
        "    \n",
        "#     plt.title('Loss')\n",
        "#     plt.xlabel('Epochs')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.legend()\n",
        "    \n",
        "#     ## Accuracy\n",
        "#     plt.figure(2)\n",
        "#     for l in acc_list:\n",
        "#         plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "#     for l in val_acc_list:    \n",
        "#         plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
        "\n",
        "#     plt.title('Accuracy')\n",
        "#     plt.xlabel('Epochs')\n",
        "#     plt.ylabel('Accuracy')\n",
        "#     plt.legend()\n",
        "#     plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu3ZNDGsB7io"
      },
      "source": [
        "# plot_history(history1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLN97KR6DUv7"
      },
      "source": [
        "#**#7.Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1atMhadXl5Np"
      },
      "source": [
        "# #Step7 Evaluate Model\n",
        "# test_loss, test_acc = model_1.evaluate(X_test,  y_test, verbose=2)\n",
        "# print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxwheYZOSJMl"
      },
      "source": [
        "# # Confusion Matrix \n",
        "\n",
        "# # Predict the values from the validation dataset\n",
        "# Y_pred = model_1.predict(X_test)  \n",
        "\n",
        "# # Convert predictions classes to one hot vectors \n",
        "# Y_pred_classes = np.argmax(Y_pred, axis = 1) \n",
        "\n",
        "# results = confusion_matrix(y_test, Y_pred_classes)\n",
        "# print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA477C_66AFr"
      },
      "source": [
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# class_names = ['Postive', 'Negative']\n",
        "# print(classification_report(y_test, Y_pred_classes, target_names = class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32yxeYPi8U9P"
      },
      "source": [
        "# Y_pred_classes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6LtkdtN30gi"
      },
      "source": [
        "#**#8.Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRZxWM7D4arI"
      },
      "source": [
        "**i)-Dropout: Change the position and value of dropout layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKVTnRAO4jDb"
      },
      "source": [
        "# hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\", output_shape=[128], \n",
        "#                            input_shape=[], dtype=tf.string)\n",
        "# model_2 = keras.Sequential()\n",
        "# model_2.add(hub_layer)\n",
        "# model_2.add(keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "# model_2.add(keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "# model_2.add(keras.layers.Dropout(0.9))\n",
        "# model_2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAM5jmcK45Mf"
      },
      "source": [
        "# opt = Adam(lr=0.01)\n",
        "# model_2.compile(optimizer = opt, loss ='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HSaI8_Z5UGg"
      },
      "source": [
        "# no_of_epcohs = 15\n",
        "# gradient_batch_size = 128\n",
        "\n",
        "# history2 = model_2.fit(X_train, \n",
        "#                    y_train,\n",
        "#                    validation_split = 0.2,\n",
        "#                    steps_per_epoch = 5,\n",
        "#                    epochs=no_of_epcohs,\n",
        "#                    batch_size=gradient_batch_size, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LvH7YUlD7tf"
      },
      "source": [
        "# plot_history(history2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdIVHjYw5f1B"
      },
      "source": [
        "# # Model Evaluation\n",
        "# test_loss, test_acc = model_2.evaluate(X_test,  y_test, verbose=2)\n",
        "# print('\\nTest accuracy:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah9lSdRf6CjC"
      },
      "source": [
        "**ii)- Batch Size: Change the value of batch size in model training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wYXDjES5o5j"
      },
      "source": [
        "# hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\", output_shape=[128], \n",
        "#                            input_shape=[], dtype=tf.string)\n",
        "# model_3 = keras.Sequential()\n",
        "# model_3.add(hub_layer)\n",
        "# model_3.add(keras.layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "# model_3.add(keras.layers.Dropout(0.5))\n",
        "# model_3.add(keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.0001)))\n",
        "# model_3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model_3.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPsp62L86ZUM"
      },
      "source": [
        "# opt = Adam(lr=0.01)\n",
        "# model_3.compile(optimizer = opt, loss ='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xeVkGUz6iRG"
      },
      "source": [
        "# no_of_epcohs = 15\n",
        "# gradient_batch_size = 32\n",
        "\n",
        "# history3 = model_3.fit(X_train, \n",
        "#                    y_train,\n",
        "#                    validation_split = 0.2,\n",
        "#                    steps_per_epoch = 5,\n",
        "#                    epochs=no_of_epcohs,\n",
        "#                    batch_size=gradient_batch_size, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGc3nPmzEYW9"
      },
      "source": [
        "# plot_history(history3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR967P687OsI"
      },
      "source": [
        "# Model Evaluation\n",
        "# test_loss, test_acc = model_3.evaluate(X_test,  y_test, verbose=2)\n",
        "# print('\\nTest accuracy:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAZLR4Sm71Dc"
      },
      "source": [
        "**# Comparision between models and reason for change is accuracy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi3DXVekJavB"
      },
      "source": [
        "<table>\n",
        "<body>\n",
        "\n",
        "<tr><td><b>Model</td><td><b>Dropouts</td><td><b>Batch Size</td><td><b> Training Accuracy</td>\n",
        " <td><b>Testing Accuracy</td><td><b>Observation</td>\n",
        "</tr>\n",
        "\n",
        "<tr><td>Model_1</td><td align=\"center\"><b>0.5</td><td align=\"center\"><b>128</td><td align=\"center\"><b>75.78%</td>\n",
        " <td align=\"center\"><b>72.17%</td><td>\n",
        "  <h7>This is the base model.<br>Training Accuracy and testing Accuracy is almost same. No overfitting or underfitting issues with the model. \n",
        " </td>\n",
        "</tr>\n",
        "\n",
        "<tr><td>Model_2</td><td align=\"center\"><b>0.9</td><td align=\"center\"><b>128</td><td align=\"center\"><b>74.69% </td>\n",
        " <td align=\"center\"><b>71.10%</td><td><P1>\n",
        "  <h7>Traning Accuracy and the Testing Accuracy is almost same. No overfiting or underfiting issues with the model. <br>Accuracy is getting less with high Dropouts parameter compare to the base model.\n",
        "</td>\n",
        "</tr>\n",
        "<tr><td>Model_3</td><td align=\"center\"><b>0.5</td><td align=\"center\"><b>32</td><td align=\"center\"><b>69.38%</td>\n",
        " <td align=\"center\"><b>70.61%</td><td>\n",
        " <h7>\n",
        " Execution time is taking more time with less batch size compare to the base model with same Epoch. \n",
        "<br>Training accuracy is slightly more compare to the base model.<br> No overfitting or underfitting issues.\n",
        "</h2>\n",
        "</td>\n",
        "</tr>\n",
        "</body>\n",
        "</table>"
      ]
    }
  ]
}